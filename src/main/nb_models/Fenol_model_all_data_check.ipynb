{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import glob\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"3\"\n",
    "\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.backend import clear_session\n",
    "from keras.datasets import mnist\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Input\n",
    "from keras.layers import Activation\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.models import Sequential, load_model, Model\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import model_from_json\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score, accuracy_score\n",
    "\n",
    "import optuna\n",
    "\n",
    "import psycopg2\n",
    "from config import *\n",
    "\n",
    "import utm\n",
    "import time\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest(lon,lat,estaciones):\n",
    "    distancias_list=[]\n",
    "    cercano=0\n",
    "    closest=10000000\n",
    "    for i in range(len(estaciones)):\n",
    "        dist=(estaciones['longitude'].iloc[i]-lon)**2+(estaciones['latitude'].iloc[i]-lat)**2\n",
    "        distancias_list.append(dist)\n",
    "        if(dist<closest):\n",
    "            closest=dist\n",
    "            cercano=estaciones['nombrecorto'].iloc[i]\n",
    "    estaciones['distancias']=distancias_list\n",
    "    return cercano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conexion = psycopg2.connect(database=db_database, \n",
    "                                user=db_user, \n",
    "                                password=db_password, \n",
    "                                host=db_host, \n",
    "                                port=db_port)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''select date, variedad, min(phenologystageid) as phenologystageid, codigocatastro as codigo \n",
    "from redfara.redfara_fenologia\n",
    "where especie='VIÑEDO VINIFICACION'\n",
    "group by date, variedad, codigo, phenologystageid;'''\n",
    "phenological_data = pd.read_sql_query(query, con=conexion).drop_duplicates()\n",
    "conexion.commit()\n",
    "phenological_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='select * from cadastral.parcelas where codigo in '+ str(list(phenological_data.codigo.unique())).replace('[','(').replace(']',')') + ';'\n",
    "cadastral_data = pd.read_sql_query(query, con=conexion)\n",
    "conexion.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cadastral_data['longitude']=cadastral_data['coordenadas_epsgwgs84'].apply(lambda x:float(x[0]))\n",
    "cadastral_data['latitude']=cadastral_data['coordenadas_epsgwgs84'].apply(lambda x:float(x[1]))\n",
    "cadastral_data=cadastral_data[['codigo', 'longitude','latitude','altitud']].drop_duplicates()\n",
    "cadastral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='select * from public.estara;'\n",
    "stations = pd.read_sql_query(query, con=conexion).drop_duplicates()\n",
    "conexion.commit()\n",
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stations['longitude']=stations.longitud.str.split(\"'|º\").apply(lambda x:int(x[0])+int(x[1])/60+int(x[2])/3600000)\n",
    "stations['longitude']=stations['longitude']*(stations.longitud.str.contains('E')*2-1)\n",
    "stations['latitude']=stations.latitud.str.split(\"'|º\").apply(lambda x:int(x[0])+int(x[1])/60+int(x[2])/3600000)\n",
    "stations['latitude']=stations['latitude']*(stations.latitud.str.contains('N')*2-1)\n",
    "stations=stations[['nombrecorto','longitude','latitude', 'altitud']]\n",
    "stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cercanias=[]\n",
    "for i in range(len(cadastral_data)):\n",
    "    cercanias.append(get_closest(cadastral_data.iloc[i].longitude,cadastral_data.iloc[i].latitude,stations))\n",
    "cadastral_data['closest']=cercanias\n",
    "cadastral_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_stations = stations[stations.nombrecorto.isin(cadastral_data.closest.unique())]\n",
    "closest_stations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lowest_year=phenological_data.date.dt.year.min()\n",
    "lowest_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='select * from public.meteorological_data WHERE anio >= ' + str(lowest_year) + ' AND estacion in ' + str(list(closest_stations.nombrecorto.unique())).replace('[','(').replace(']',')') + ';'\n",
    "meteorological_data = pd.read_sql_query(query, con=conexion).drop_duplicates()\n",
    "conexion.commit()\n",
    "meteorological_data = meteorological_data.drop(['ubi', 'season', 'hourFrac_sum'], axis=1)\n",
    "variables_diarias_min=['tmed_min', 'rad_min']\n",
    "variables_diarias_max=['tmed_max', 'rad_max']\n",
    "variables_diarias_mean=['tmed_mean', 'rad_mean', 'wind_N', 'wind_NE', 'wind_E','wind_SE', 'wind_S', 'wind_SW', \n",
    "                        'wind_W', 'wind_NW']\n",
    "variables_semanales=['gdd_4.5_t0_Tbase_sum',\n",
    "       'gdd_4.5_t0_TbaseMax_sum', 'gdd_4.5_1_Tbase_sum',\n",
    "       'gdd_4.5_1_TbaseMax_sum', 'gdd_4.5_2_Tbase_sum',\n",
    "       'gdd_4.5_2_TbaseMax_sum', 'gdd_10.0_t0_Tbase_sum',\n",
    "       'gdd_10.0_t0_TbaseMax_sum', 'gdd_10.0_1_Tbase_sum',\n",
    "       'gdd_10.0_1_TbaseMax_sum', 'gdd_10.0_2_Tbase_sum',\n",
    "       'gdd_10.0_2_TbaseMax_sum', 'chillingDD_7.0_t0_Tbase_sum',\n",
    "       'chillingDD_7.0_t0_Tbasemin_sum', 'chillingDD_7.0_t0_Utah_sum',\n",
    "       'chillingDD_7.0_1_Tbase_sum', 'chillingDD_7.0_1_Tbasemin_sum',\n",
    "       'chillingDD_7.0_1_Utah_sum', 'chillingDD_7.0_2_Tbase_sum',\n",
    "       'chillingDD_7.0_2_Tbasemin_sum', 'chillingDD_7.0_2_Utah_sum', 'rad_sum',\n",
    "       'precip_sum', 'winkler_4.5_Tbase', 'winkler_4.5_TbaseMax',\n",
    "       'winkler_10.0_Tbase', 'winkler_10.0_TbaseMax',\n",
    "       'gdd_4.5_t0_Tbase_sum_Cumm', 'gdd_4.5_t0_TbaseMax_sum_Cumm',\n",
    "       'gdd_4.5_1_Tbase_sum_Cumm', 'gdd_4.5_1_TbaseMax_sum_Cumm',\n",
    "       'gdd_4.5_2_Tbase_sum_Cumm', 'gdd_4.5_2_TbaseMax_sum_Cumm',\n",
    "       'gdd_10.0_t0_Tbase_sum_Cumm', 'gdd_10.0_t0_TbaseMax_sum_Cumm',\n",
    "       'gdd_10.0_1_Tbase_sum_Cumm', 'gdd_10.0_1_TbaseMax_sum_Cumm',\n",
    "       'gdd_10.0_2_Tbase_sum_Cumm', 'gdd_10.0_2_TbaseMax_sum_Cumm',\n",
    "       'chillingDD_7.0_t0_Tbase_sum_Cumm',\n",
    "       'chillingDD_7.0_t0_Tbasemin_sum_Cumm',\n",
    "       'chillingDD_7.0_t0_Utah_sum_Cumm', 'chillingDD_7.0_1_Tbase_sum_Cumm',\n",
    "       'chillingDD_7.0_1_Tbasemin_sum_Cumm', 'chillingDD_7.0_1_Utah_sum_Cumm',\n",
    "       'chillingDD_7.0_2_Tbase_sum_Cumm', 'chillingDD_7.0_2_Tbasemin_sum_Cumm',\n",
    "       'chillingDD_7.0_2_Utah_sum_Cumm', 'rad__t0__Cumm', 'rad__1__Cumm',\n",
    "       'rad__2__Cumm', 'precip__t0__Cumm', 'precip__1__Cumm',\n",
    "       'precip__2__Cumm', 'winkler_4.5_t0_Tbase_Cumm',\n",
    "       'winkler_4.5_t0_TbaseMax_Cumm', 'winkler_4.5_1_Tbase_Cumm',\n",
    "       'winkler_4.5_1_TbaseMax_Cumm', 'winkler_4.5_2_Tbase_Cumm',\n",
    "       'winkler_4.5_2_TbaseMax_Cumm', 'winkler_10.0_t0_Tbase_Cumm',\n",
    "       'winkler_10.0_t0_TbaseMax_Cumm', 'winkler_10.0_1_Tbase_Cumm',\n",
    "       'winkler_10.0_1_TbaseMax_Cumm', 'winkler_10.0_2_Tbase_Cumm',\n",
    "       'winkler_10.0_2_TbaseMax_Cumm']\n",
    "meteorological_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meteorological_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_meteo_buenos_list=[]\n",
    "n_dias_atras=15\n",
    "n_dias_alante=8\n",
    "for estacion in meteorological_data['estacion'].unique():\n",
    "    datos_est=meteorological_data[meteorological_data.estacion==estacion].sort_values('fecha').set_index('fecha')\n",
    "    datos_meteo_buenos_est_list=[datos_est[['estacion']]]\n",
    "    for var in variables_diarias_min:\n",
    "        datos_var_est=datos_est[[var]].resample('1D').min()\n",
    "        for i in range(1,n_dias_atras):\n",
    "            datos_var_est[var + \" \" + str(i) + \"_dias_atras\"]=datos_var_est[var].resample('1D').min().shift(i)\n",
    "        for i in range(1,n_dias_alante):\n",
    "            datos_var_est[var + \" \" + str(i) + \"_dias_adelante\"]=datos_var_est[var].resample('1D').min().shift(-i)\n",
    "        datos_meteo_buenos_est_list.append(datos_var_est)\n",
    "    for var in variables_diarias_max:\n",
    "        datos_var_est=datos_est[[var]].resample('1D').max()\n",
    "        for i in range(1,n_dias_atras):\n",
    "            datos_var_est[var + \" \" + str(i) + \"_dias_atras\"]=datos_var_est[var].resample('1D').max().shift(i)\n",
    "        for i in range(1,n_dias_alante):\n",
    "            datos_var_est[var + \" \" + str(i) + \"_dias_adelante\"]=datos_var_est[var].resample('1D').max().shift(-i)\n",
    "        datos_meteo_buenos_est_list.append(datos_var_est)\n",
    "    for var in variables_diarias_mean:\n",
    "        datos_var_est=datos_est[[var]].resample('1D').max()\n",
    "        for i in range(1,n_dias_atras):\n",
    "            datos_var_est[var + \" \" + str(i) + \"_dias_atras\"]=datos_var_est[var].resample('1D').max().shift(i)\n",
    "        for i in range(1,n_dias_alante):\n",
    "            datos_var_est[var + \" \" + str(i) + \"_dias_adelante\"]=datos_var_est[var].resample('1D').max().shift(-i)\n",
    "        datos_meteo_buenos_est_list.append(datos_var_est)\n",
    "    for var in variables_semanales:\n",
    "        datos_var_est=datos_est[[var]].resample('1D').max()\n",
    "        for i in range(1,1+n_dias_atras//7):\n",
    "            datos_var_est[var + \" \" + str(i) + \"_semanas_atras\"]=datos_var_est[var].resample('1D').ffill().shift(i*7)\n",
    "        for i in range(1,1+n_dias_alante//7):\n",
    "            datos_var_est[var + \" \" + str(i) + \"_semanas_adelante\"]=datos_var_est[var].resample('1D').ffill().shift(-i*7)\n",
    "        datos_meteo_buenos_est_list.append(datos_var_est)\n",
    "        \n",
    "    datos_var_est=pd.concat(datos_meteo_buenos_est_list,axis=1).reset_index()\n",
    "    datos_meteo_buenos_list.append(datos_var_est)\n",
    "datos_meteo_buenos=pd.concat(datos_meteo_buenos_list).dropna()\n",
    "datos_meteo_buenos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_part=pd.merge(phenological_data.reset_index(), cadastral_data, left_on='codigo', right_on='codigo', how='outer', indicator=True)\n",
    "datos_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_part2=datos_part[datos_part._merge=='both']\n",
    "datos_part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_campos=[]\n",
    "for campo in datos_part2.codigo.unique():\n",
    "    datos_part3=datos_part2[datos_part2.codigo==campo]\n",
    "    datos_campos.append(datos_part3.sort_values('date').set_index('date').resample('1D').ffill().dropna())\n",
    "    \n",
    "datos_part=pd.concat(datos_campos).reset_index()\n",
    "datos_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_part['anio']=datos_part['date'].dt.year\n",
    "datos_part['dia']=datos_part['date'].dt.dayofyear\n",
    "datos_part=datos_part.drop(columns=['index','_merge','date'])\n",
    "datos_part=pd.get_dummies(datos_part,columns=['variedad'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_meteo_buenos['anio']=datos_meteo_buenos.fecha.dt.year\n",
    "datos_meteo_buenos['dia']=datos_meteo_buenos.fecha.dt.dayofyear\n",
    "datos_total=pd.merge(datos_part, datos_meteo_buenos, left_on=['closest','anio','dia'], right_on=['estacion','anio','dia'])\n",
    "datos_total=datos_total.drop(['closest','fecha','estacion'],axis=1)\n",
    "datos_total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query='''select codigo, date, AVG(min) as min, AVG(max) as max, AVG(mean) as mean, AVG(std) as std, AVG(meidan) as median from \n",
    "public.copernicus_nvdi where pixels_array is not null and tesela is not null\n",
    "group by codigo, date;'''\n",
    "satelital_data = pd.read_sql_query(query, con=conexion).drop_duplicates()\n",
    "conexion.commit()\n",
    "satelital_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdatas_list=[]\n",
    "for campo in satelital_data.codigo.unique():\n",
    "    subdata=satelital_data[satelital_data.codigo==campo]\n",
    "    subdata['date']=pd.to_datetime(subdata['date'],format='%Y-%m-%d')\n",
    "    subdata['date2']=subdata['date']\n",
    "    subdata=subdata.sort_values('date').set_index('date').resample('1D').ffill().reset_index()\n",
    "    subdata['diff']=(subdata['date']-subdata['date2']).dt.days\n",
    "    subdatas_list.append(subdata[subdata['diff']<21].drop(columns=['diff','date2']))\n",
    "satelital_data2=pd.concat(subdatas_list)\n",
    "satelital_data2['dia']=satelital_data2.date.dt.dayofyear\n",
    "satelital_data2['anio']=satelital_data2.date.dt.year\n",
    "satelital_data2=satelital_data2.drop(columns=['date'])\n",
    "satelital_data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conexion.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_total2=pd.merge(datos_total, satelital_data2, left_on=['codigo','anio','dia'], right_on=['codigo','anio','dia'])\n",
    "# datos_total2=datos_total2.drop(columns=['codigo'])\n",
    "datos_total2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_total2.columns[400:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_total2.to_csv('/data/proyectos/GRAPEVINE/all_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(model,model_chars,data):\n",
    "    variedades=[col for col in data.columns if 'variedad_' in col]\n",
    "    variables_basic=['phenologystageid','dia', 'min', 'max', 'mean', 'std', 'median']+variedades\n",
    "    medidas=variables_basic\n",
    "    \n",
    "    altitud=model_chars['params_Altitud']\n",
    "    latitud=model_chars['params_Latitud']\n",
    "    longitud=model_chars['params_Longitud']\n",
    "    if(longitud):\n",
    "        medidas.append('longitude')\n",
    "    if(latitud):\n",
    "        medidas.append('latitude')\n",
    "    if(altitud):\n",
    "        medidas.append('altitud')\n",
    "        \n",
    "    if model_chars['params_Acumuladas']:\n",
    "        \n",
    "        inicio=model_chars['params_Inicio mediciones']\n",
    "        suffix=''\n",
    "        name_vars=[]\n",
    "        \n",
    "        chilling=model_chars['params_Chilling']\n",
    "        winkler=model_chars['params_Winkler']\n",
    "        gdd=model_chars['params_gdd']\n",
    "        \n",
    "        acumulativo=model_chars['params_Acumulativo']\n",
    "        if (acumulativo):\n",
    "            suffix='_Cumm'\n",
    "            if model_chars['params_Precipitaciones']:\n",
    "                name_vars.append('precip__'+inicio+'_')\n",
    "            if model_chars['params_Radiacion']:\n",
    "                name_vars.append('rad__'+inicio+'_')\n",
    "                \n",
    "        if (winkler|gdd):\n",
    "            tbase=model_chars['params_Tbase']\n",
    "            temperatura_inicio=str(model_chars['params_Temperatura inicio'])\n",
    "        if (chilling):\n",
    "            tbase_chill=model_chars['params_Tbase_chilling']\n",
    "            name_vars.append('chillingDD_7.0_'+inicio+'_' + tbase_chill +'_sum')\n",
    "        if (winkler):\n",
    "            if acumulativo:\n",
    "                name_vars.append('winkler_'+temperatura_inicio+'_'+inicio+'_' + tbase)\n",
    "            else:\n",
    "                name_vars.append('winkler_'+temperatura_inicio+'_' + tbase)\n",
    "        if (gdd):\n",
    "            name_vars.append('gdd_'+temperatura_inicio+'_'+inicio+'_' + tbase+'_sum')\n",
    "       \n",
    "        if len(name_vars)>0:\n",
    "            semanas_list=[]\n",
    "            for i in range(1,3):\n",
    "                if model_chars['params_'+str(i)+'_semanas_atras']:\n",
    "                    semanas_list.append(' '+str(i)+'_semanas_atras')\n",
    "            if model_chars['params_1_semanas_adelante']:\n",
    "                    semanas_list.append(' 1_semanas_adelante')\n",
    "                    \n",
    "            for name_var in name_vars:\n",
    "                medidas.append(name_var+suffix)\n",
    "                for semana in semanas_list:\n",
    "                    medidas.append(name_var+suffix+semana)\n",
    "        \n",
    "    else:\n",
    "        name_vars=[]    \n",
    "        if model_chars['params_Temperatura']:\n",
    "            if model_chars['params_Temperatura_media']:\n",
    "                name_vars.append('tmed_mean')\n",
    "            if model_chars['params_Temperatura_min']:\n",
    "                name_vars.append('tmed_min')\n",
    "            if model_chars['params_Temperatura_max']:\n",
    "                name_vars.append('tmed_max')\n",
    "\n",
    "        if model_chars['params_Radiacion']:\n",
    "            if model_chars['params_Radiacion_media']:\n",
    "                name_vars.append('rad_mean')\n",
    "            if model_chars['params_Radiacion_min']:\n",
    "                name_vars.append('rad_min')\n",
    "            if model_chars['params_Radiacion_max']:\n",
    "                name_vars.append('rad_max')\n",
    "\n",
    "        if model_chars['params_Viento']:\n",
    "            if model_chars['params_Viento_norte']:\n",
    "                name_vars.append('wind_N')\n",
    "            if model_chars['params_Viento_noreste']:\n",
    "                name_vars.append('wind_NE')\n",
    "            if model_chars['params_Viento_este']:\n",
    "                name_vars.append('wind_E')\n",
    "            if model_chars['params_Viento_sureste']:\n",
    "                name_vars.append('wind_SE')\n",
    "            if model_chars['params_Viento_sur']:\n",
    "                name_vars.append('wind_S')\n",
    "            if model_chars['params_Viento_suroeste']:\n",
    "                name_vars.append('wind_SW')\n",
    "            if model_chars['params_Viento_oeste']:\n",
    "                name_vars.append('wind_W')\n",
    "            if model_chars['params_Viento_noroeste']:\n",
    "                name_vars.append('wind_NW')\n",
    "        \n",
    "        if len(name_vars)>0:\n",
    "            dias_vars=[]\n",
    "            for i in range(1,15):\n",
    "                if model_chars['params_'+str(i)+'_dias_atras']:\n",
    "                    dias_vars.append(' ' + str(i) + '_dias_atras')\n",
    "            for i in range(1,8):\n",
    "                if model_chars['params_'+str(i)+'_dias_adelante']:\n",
    "                    dias_vars.append(' ' + str(i) + '_dias_adelante')\n",
    "\n",
    "            for name_var in name_vars:\n",
    "                medidas.append(name_var)\n",
    "                for dia_var in dias_vars:\n",
    "                    medidas.append(name_var+dia_var)\n",
    "\n",
    "    medidas.append('dias_hasta')\n",
    "    data=data[medidas]#.dropna()\n",
    "                   \n",
    "    \n",
    "    X_vali=data.drop(['dias_hasta'], axis=1).values\n",
    "    Y_vali=data['dias_hasta'].values\n",
    "\n",
    "    \n",
    "    \n",
    "    preds = model.predict(X_vali)\n",
    "\n",
    "    SCORE=r2_score(Y_vali,preds)\n",
    "    print(\"R^2: \",SCORE)\n",
    "    \n",
    "    return SCORE, medidas, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_no_val=datos_total2[datos_total2.anio<=2020]\n",
    "datos_no_val.phenologystageid=datos_no_val.phenologystageid.replace({9.0:0.0})\n",
    "datos_val=datos_total2[datos_total2.anio>2020]\n",
    "datos_val.phenologystageid=datos_val.phenologystageid.replace({9.0:0.0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mejores_modelos={}\n",
    "\n",
    "for estado_fen in range(1,9):\n",
    "    temp=datos_val.copy()\n",
    "\n",
    "    datos_list=[]\n",
    "    for campaña in temp.anio.unique():\n",
    "        datos_camp=temp[temp['anio']==campaña]\n",
    "        for id_terr in datos_camp.codigo.unique():\n",
    "            datos_camp_terr=datos_camp[datos_camp['codigo']==id_terr]\n",
    "            x=datos_camp_terr[datos_camp_terr['phenologystageid']>=estado_fen]['dia'].values\n",
    "            momento=0\n",
    "            if len(x>0):\n",
    "                momento=np.min(x)\n",
    "            datos_camp_terr['dias_hasta']=momento-datos_camp_terr['dia']\n",
    "            datos_list.append(datos_camp_terr[datos_camp_terr['dias_hasta']>0])\n",
    "\n",
    "    datos_check=pd.concat(datos_list)\n",
    "#     datos_check=datos_check[datos_check.anio==2018]\n",
    "\n",
    "    modelos_estado=pd.read_csv(f'/data/proyectos/GRAPEVINE/Models/all_data/Intento1/Estado_feno_' + \n",
    "                               str(estado_fen) + '/resumen_optuna-estado'+str(estado_fen)+'-r2-dias.csv')\n",
    "    modelos_estado=modelos_estado.sort_values('value',ascending=False)\n",
    "    modelo_elegido=modelos_estado.iloc[0]\n",
    "    \n",
    "    \n",
    "    if (len(glob.glob('/data/proyectos/GRAPEVINE/Models/all_data/Intento1/Estado_feno_' + str(estado_fen) + '/model-estado'+ str(estado_fen) +'-'+str(modelo_elegido['value'])[:10]+'*.json'))>0):\n",
    "        mejores_modelos[estado_fen]={}\n",
    "        mejores_modelos[estado_fen]['dias_hasta']=datos_check['dias_hasta']\n",
    "        mejores_modelos[estado_fen]['params']=modelo_elegido\n",
    "        json_file = open(glob.glob('/data/proyectos/GRAPEVINE/Models/all_data/Intento1/Estado_feno_' + str(estado_fen) + '/model-estado'+ str(estado_fen) +'-'+str(modelo_elegido['value'])[:10]+'*.json')[0], 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        model = model_from_json(loaded_model_json)\n",
    "        # load weights into new model\n",
    "        model.load_weights(glob.glob('/data/proyectos/GRAPEVINE/Models/all_data/Intento1/Estado_feno_' + str(estado_fen)  + '/model-estado'+ str(estado_fen) +'-'+str(modelo_elegido['value'])[:10]+'*.h5')[0])\n",
    "        mejores_modelos[estado_fen]['modelo']=model\n",
    "\n",
    "        print(modelo_elegido['value'])\n",
    "        mejores_modelos[estado_fen]['value'], mejores_modelos[estado_fen]['medidas'], mejores_modelos[estado_fen]['preds']=eval_model(model,modelo_elegido,datos_check)\n",
    "    else:\n",
    "        print(\"No hay modelos para el estado fenológico:\", estado_fen)\n",
    "    print('#'*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "with pd.ExcelWriter(\"predicciones_y reales_por_estados_para_francis.xlsx\") as writer:\n",
    "    for estado_fen in range(1,9):\n",
    "        plt.hist(mejores_modelos[estado_fen]['dias_hasta']-mejores_modelos[estado_fen]['preds'][:,0], bins=30)\n",
    "        plt.title('Phenological State ' + str(estado_fen))\n",
    "        plt.xlabel(\"Error\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.show()\n",
    "        pd.DataFrame([mejores_modelos[estado_fen]['dias_hasta'].values,mejores_modelos[estado_fen]['preds'][:,0]],\n",
    "                 index=['dias_hasta','prediction']).T.to_excel(writer, sheet_name='Estado_feno_'+str(estado_fen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estado_fen in range(1,9):\n",
    "    plt.hist(mejores_modelos[estado_fen]['dias_hasta']-np.mean(mejores_modelos[estado_fen]['dias_hasta']), bins=30)\n",
    "    plt.title('Phenological State ' + str(estado_fen))\n",
    "    plt.xlabel(\"Difference with the mean value\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors_by_day=[]\n",
    "for estado_fen in range(1,9):\n",
    "    df=pd.DataFrame([mejores_modelos[estado_fen]['dias_hasta'].values,mejores_modelos[estado_fen]['preds'][:,0]],\n",
    "                 index=['days to phenological state','prediction']).T\n",
    "    df['error_estado_feno'+str(estado_fen)]=abs(df['days to phenological state']-df['prediction'])\n",
    "    df.groupby('days to phenological state').mean()[['error_estado_feno'+str(estado_fen)]].sort_index().plot(legend=False,\n",
    "                                            title='Errors relative to phenological state ' + str(estado_fen) + ' proximity',\n",
    "                                            ylabel='Mean error')\n",
    "    errors_by_day.append(df.groupby('days to phenological state').mean()[['error_estado_feno'+str(estado_fen)]])\n",
    "    \n",
    "pd.concat(errors_by_day,axis=1).to_csv('errores_medios_por_dia_para_Francisco.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for estado_fen in range(1,9):\n",
    "    print(\"VARIABLES UTILIZADAS POR EL MODELO QUE PREDICE EL ESTADO FENOLÓGICO\", estado_fen, \":\")\n",
    "    print('-'*120)\n",
    "    print(mejores_modelos[estado_fen]['medidas'])\n",
    "    print('#'*120)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(r2,index=range(1,9)).to_csv('r2_para_francisco.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = pd.DataFrame(r2,index=range(1,9)).plot(kind='bar', ylim=(0.7,1), legend=False, width=0.8, \n",
    "                                            title='R^2 for each phenology state')\n",
    "for p in ax.patches:\n",
    "    ax.annotate(str(np.round(p.get_height(),3)), (p.get_x() * 1.005, p.get_height() * 1.005))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp=datos_val.copy()\n",
    "\n",
    "datos_list=[]\n",
    "for campaña in temp.anio.unique():\n",
    "    datos_camp=temp[temp['anio']==campaña]\n",
    "    for id_terr in datos_camp.codigo.unique():\n",
    "        datos_camp_terr=datos_camp[datos_camp['codigo']==id_terr].sort_values('dia')\n",
    "        datos_camp_terr['future_pheno']=datos_camp_terr['phenologystageid'].shift(7)\n",
    "        datos_list.append(datos_camp_terr.dropna())\n",
    "datos_final=pd.concat(datos_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_final=datos_final[datos_final.future_pheno>=datos_final.phenologystageid]\n",
    "datos_final=datos_final[datos_final.future_pheno<=7]#[['phenologystageid','future_pheno']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key in mejores_modelos.keys():\n",
    "    print(key)\n",
    "    datos_final['prediccion_'+str(key)]=mejores_modelos[key]['modelo'].predict(datos_final[mejores_modelos[key]['medidas'][:-1]], verbose=1)\n",
    "#     for i in range(len(datos_final)):\n",
    "        \n",
    "        \n",
    "datos_final    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_final.columns[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "horizon=7\n",
    "preds_feno=datos_final.phenologystageid.values\n",
    "for i in range(len(datos_final)):\n",
    "    for key in mejores_modelos.keys():\n",
    "        if key>preds_feno[i]:\n",
    "            if datos_final['prediccion_'+str(key)].iloc[i]<horizon:\n",
    "                preds_feno[i]=key\n",
    "                \n",
    "datos_final['preds_feno']=preds_feno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, matthews_corrcoef, roc_auc_score, roc_curve, confusion_matrix, classification_report, f1_score,recall_score\n",
    "\n",
    "confusion_matrix(datos_final['future_pheno'],datos_final['preds_feno'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import seaborn as sns\n",
    "cf_matrix=confusion_matrix(datos_final['future_pheno'],datos_final['preds_feno'])\n",
    "sns.heatmap(cf_matrix, annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(20,20))  \n",
    "corres=datos_total2[['dia', 'tmed_min', 'tmed_max', 'tmed_mean', 'rad_min', 'rad_max', 'rad_mean','gdd_4.5_t0_Tbase_sum_Cumm',\n",
    " 'gdd_4.5_t0_TbaseMax_sum_Cumm','gdd_4.5_1_Tbase_sum_Cumm','gdd_4.5_1_TbaseMax_sum_Cumm','gdd_4.5_2_Tbase_sum_Cumm',\n",
    " 'gdd_4.5_2_TbaseMax_sum_Cumm','gdd_10.0_t0_Tbase_sum_Cumm','gdd_10.0_t0_TbaseMax_sum_Cumm','gdd_10.0_1_Tbase_sum_Cumm',\n",
    " 'gdd_10.0_1_TbaseMax_sum_Cumm','gdd_10.0_2_Tbase_sum_Cumm','gdd_10.0_2_TbaseMax_sum_Cumm',\n",
    " 'chillingDD_7.0_t0_Tbase_sum_Cumm','chillingDD_7.0_t0_Tbasemin_sum_Cumm','chillingDD_7.0_t0_Utah_sum_Cumm',\n",
    " 'chillingDD_7.0_1_Tbase_sum_Cumm','chillingDD_7.0_1_Tbasemin_sum_Cumm','chillingDD_7.0_1_Utah_sum_Cumm',\n",
    " 'chillingDD_7.0_2_Tbase_sum_Cumm','chillingDD_7.0_2_Tbasemin_sum_Cumm','chillingDD_7.0_2_Utah_sum_Cumm' , 'rad__t0__Cumm',\n",
    " 'rad__1__Cumm', 'rad__2__Cumm', 'precip__t0__Cumm','precip__1__Cumm', 'precip__2__Cumm', 'winkler_4.5_t0_Tbase_Cumm',\n",
    " 'winkler_4.5_t0_TbaseMax_Cumm','winkler_4.5_1_Tbase_Cumm','winkler_4.5_1_TbaseMax_Cumm','winkler_4.5_2_Tbase_Cumm',\n",
    " 'winkler_4.5_2_TbaseMax_Cumm','winkler_10.0_t0_Tbase_Cumm','winkler_10.0_t0_TbaseMax_Cumm','winkler_10.0_1_Tbase_Cumm',\n",
    " 'winkler_10.0_1_TbaseMax_Cumm','winkler_10.0_2_Tbase_Cumm','winkler_10.0_2_TbaseMax_Cumm', 'wind_N','wind_NE','wind_E',\n",
    " 'wind_SE','wind_S','wind_SW','wind_W','wind_NW', 'longitude', 'latitude', 'altitud', 'phenologystageid']].corr().fillna(0)\n",
    "sns.heatmap(corres[corres.columns[-2:]], annot=False, vmin=-1, vmax=1, square=True, ax=ax, cmap='seismic', linewidths=.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
